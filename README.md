# Transformer Experiments Overview

This repository will explore different model architectures for image segmentation, which will build into Vision Transformers and my experimental implementations of them. This will provide a good benchmark to compare models. Currently, I am using the OxfordIIIPet dataset.

I will divide this repository into two sections with multiple experiments, each exploring a different model architecture:

Section 1 (Image Classification):
 - Experiment 1: CNN
 - Experiment 2: Resnet
 - Experiment 5: Vision Transformer
 - Experiment 6: Inception ViT
 - Experiment 7: QKV ViT

Section 2 (Image Segmentation):
 - Experiment 1: CNN
 - Experiment 2: Resnet
 - Experiment 3: Unet
 - Experiment 4: Unet w/ Attention
 - Experiment 5: Vision Transformer
 - Experiment 6: Inception ViT
 - Experiment 7: QKV ViT

# Section 1 - Image Classification

## Hyperparameters

## Experiment 1 - CNN

Currently a work in progress.

### Architecture

### Results

## TODO: References
 - https://www.kaggle.com/code/dhananjay3/image-segmentation-from-scratch-in-pytorch
 - https://github.com/pytorch/vision/blob/main/torchvision/models/vision_transformer.py
 - https://viso.ai/deep-learning/vision-transformer-vit/
 - https://theaisummer.com/medical-segmentation-transformers/
 - https://github.com/The-AI-Summer/self-attention-cv/blob/5246e550ecb674f60df76a6c1011fde30ded7f44/self_attention_cv/UnetTr/UnetTr.py